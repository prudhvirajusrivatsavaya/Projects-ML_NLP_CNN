{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import nltk\n",
    "import itertools\n",
    "from joblib import dump\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.4f}\".format(x)})\n",
    "n_jobs = -1\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "labels_dict = {'Football': 0, 'Business': 1, 'Politics': 2, 'Film': 3, 'Technology': 4}\n",
    "labels_dict_inverse = {number: label for label, number in labels_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365dfa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom ROC AUC scoring for multiclass predictions\n",
    "def multiclass_roc_auc(truth, pred):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "\n",
    "    return roc_auc_score(truth, pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using multiple measures\n",
    "# Macro averaging is used for a better estimation\n",
    "scoring = {'Accuracy': 'accuracy', 'Precision': 'precision_macro', 'Recall': 'recall_macro',\n",
    "           'F-Measure': 'f1_macro',\n",
    "           'AUC': make_scorer(multiclass_roc_auc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06119c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(subset):\n",
    "    path = ''\n",
    "    if subset == 'train':\n",
    "        path = 'BBC News Train.csv'\n",
    "        df = pd.read_csv(path, usecols=['ArticleId', 'Text'])\n",
    "        return df['Text'], df['ArticleId']\n",
    "    elif subset == 'test':\n",
    "        path = 'BBC News Test.csv'\n",
    "        df = pd.read_csv(path, usecols=['ArticleId', 'Text'])\n",
    "        return df['ArticleId'], df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ad093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(corpus, method):\n",
    "    if method == 'bow':\n",
    "        print('Vectorizing train corpus with BOW model...')\n",
    "        bow_vectorizer = CountVectorizer()\n",
    "        bow_corpus = bow_vectorizer.fit_transform(corpus)\n",
    "        return bow_vectorizer, bow_corpus\n",
    "    elif method == 'svd':\n",
    "        # Vectorizer which ignores words that occur in less than 600 documents (around ~5% of documents)\n",
    "        # This is to avoid memory errors when transforming the matrix with SVD\n",
    "        # The desired variance is achieved around 500 components.\n",
    "        svd_vectorizer = CountVectorizer(stop_words='english', min_df=600)\n",
    "        print('Vectorizing train corpus with min_df = 600 ...')\n",
    "        min_df_corpus = svd_vectorizer.fit_transform(corpus)\n",
    "        print('Original matrix shape: ', min_df_corpus.shape)\n",
    "        # SVD, for text classification the optimal value for the n_components attribute is 100 according to sklearn doc\n",
    "        svd = TruncatedSVD(n_components=100, n_iter=5)\n",
    "        print('Performing SVD on train corpus...')\n",
    "        svd_corpus = svd.fit_transform(min_df_corpus)\n",
    "        print('Corpus shape after SVD: ', svd_corpus.shape)\n",
    "        print('Explained variance ratio is: ', svd.explained_variance_ratio_.sum())\n",
    "        return svd, svd_corpus\n",
    "    elif method == 'tfidf':\n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        tfidf_corpus = tfidf_vectorizer.fit_transform(corpus)\n",
    "        # Save to disk, this was the most accurate vectorizer when used with the Ridgeclassifier\n",
    "        dump(tfidf_vectorizer, 'vectorizer.joblib')\n",
    "        return tfidf_vectorizer, tfidf_corpus\n",
    "    elif method == 'w2v':\n",
    "        # W2V MODEL\n",
    "        # Tokenize sentences\n",
    "        print('Tokenizing the corpus and training w2v model...')\n",
    "        tokenized_corpus = [word_tokenize(article) for article in corpus]\n",
    "        # Learn word vectors from the corpus, dimension is 100\n",
    "        model = Word2Vec(tokenized_corpus, vector_size=100, window=5, min_count=5, workers=4)\n",
    "        model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=5)\n",
    "        # Transform the articles in the corpus to the corresponding average vectors\n",
    "        X = []\n",
    "        print('Converting documents to vectors...')\n",
    "        article_counter = 0\n",
    "        for article in tokenized_corpus:\n",
    "            if len(article) > 0:\n",
    "                doc = [word for word in article if word in model.wv]\n",
    "            else:\n",
    "                doc = ['empty']\n",
    "            article_counter += 1\n",
    "            # Average of each vector\n",
    "            w2v_article = np.mean(model.wv[doc], axis=0)\n",
    "            X.append(w2v_article)\n",
    "\n",
    "        # Sanity check and conversion to numpy array\n",
    "        print('Processed this number of articles: ', len(X))\n",
    "        w2v_corpus = np.array(X)\n",
    "        print('Train corpus shape after word2vec conversion', w2v_corpus.shape)\n",
    "        return model, w2v_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa4268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_classifier(corpus, labels, clf):\n",
    "    if clf == 'svm':\n",
    "        # Train SVM and evaluate with 10fold\n",
    "        # Dual = False helps speed up the process\n",
    "        print('Training SVM classifier...')\n",
    "        svm_clf = LinearSVC(dual=False)\n",
    "        svm_score = cross_validate(svm_clf, corpus, labels, cv=10, scoring=scoring, n_jobs=n_jobs)\n",
    "        return svm_score\n",
    "    elif clf == 'random_forest':\n",
    "        print('Training Random Forest Classifier...')\n",
    "        forest_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=n_jobs)\n",
    "        print('Predicting with Random Forest...')\n",
    "        forest_score = cross_validate(forest_clf, corpus, labels, cv=10, scoring=scoring, n_jobs=n_jobs)\n",
    "        return forest_score\n",
    "    elif clf == 'ridge':\n",
    "        # Custom method using ridge classifier\n",
    "        # After multiple tests, this turned out to be the most successful one metrics-wise\n",
    "        # Some preprocessing is also done here, by using stop words to remove irrelevant words from the vocabulary\n",
    "        print('Training custom ridge classifier (for benchmarking against the other ones)')\n",
    "        ridge_clf = RidgeClassifier()\n",
    "        ridge_clf.fit(corpus, labels)\n",
    "        ridge_clf_score = cross_validate(ridge_clf, corpus, labels, cv=10, scoring=scoring,\n",
    "                                         n_jobs=n_jobs,\n",
    "                                         verbose=10)\n",
    "        dump(ridge_clf, 'ridge_classifier.joblib')\n",
    "        return ridge_clf, ridge_clf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e75ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(score_list):\n",
    "    results = []\n",
    "    for clf_score in score_list:\n",
    "        clf_results = {'Accuracy': float(\"{0:.4f}\".format(np.mean(clf_score['test_Accuracy']))),\n",
    "                       'Precision': float(\"{0:.4f}\".format(np.mean(clf_score['test_Precision']))),\n",
    "                       'Recall': float(\"{0:.4f}\".format(np.mean(clf_score['test_Recall']))),\n",
    "                       'F-Measure': float(\"{0:.4f}\".format(np.mean(clf_score['test_F-Measure']))),\n",
    "                       'AUC': float(\"{0:.4f}\".format(np.mean(clf_score['test_AUC'])))}\n",
    "        results.append(clf_results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_file(results):\n",
    "    # Create EvaluationMetric_10fold csv file\n",
    "    with open('EvaluationMetric_10fold.csv', 'w', encoding='utf8', newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "        accuracy_line = ['Accuracy']\n",
    "        precision_line = ['Precision']\n",
    "        recall_line = ['Recall']\n",
    "        fmeasure_line = ['F-Measure']\n",
    "        auc_line = ['AUC']\n",
    "        for result_dict in results:\n",
    "            accuracy_line.append(result_dict['Accuracy'])\n",
    "            precision_line.append(result_dict['Precision'])\n",
    "            recall_line.append(result_dict['Recall'])\n",
    "            fmeasure_line.append(result_dict['F-Measure'])\n",
    "            auc_line.append(result_dict['AUC'])\n",
    "        # Header\n",
    "        writer.writerow(\n",
    "            ['Statistic Measure', 'SVM(BoW)', 'Random Forest(BoW)', 'SVM(SVD)', 'Random Forest(SVD)', 'SVM(W2V)',\n",
    "             'Random Forest(W2V)', 'My Method'])\n",
    "        # One line for each metric\n",
    "        for row in [accuracy_line, precision_line, recall_line,fmeasure_line, auc_line]:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9896139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(corpus, clf, vectorizer):\n",
    "    print('Transforming test corpus...')\n",
    "    test_corpus = vectorizer.transform(corpus)\n",
    "    print('Predicting on test set...')\n",
    "    predictions = clf.predict(test_corpus)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testset_categories_file(test_ids, predictions):\n",
    "    # Create testSet_categories csv\n",
    "    # Mapping is as in the train set\n",
    "    with open('testSet_categories.csv', 'w', encoding='utf8', newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "        # Header\n",
    "        writer.writerow(['Test_Document_ID', 'Predicted_Category'])\n",
    "        for doc_id, prediction in zip(test_ids, predictions):\n",
    "            writer.writerow([doc_id, labels_dict_inverse[prediction]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575285b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load train data\n",
    "    corpus, labels = load_dataset(subset='train')\n",
    "    labels.replace(labels_dict, inplace=True)\n",
    "    print(corpus, labels)\n",
    "    print('Number of documents: ', len(labels))\n",
    "    # Construct dicts for all the vectorizers and classifiers that will be tested\n",
    "    corpus_dict = {'bow': [], 'svd': [], 'w2v': []}\n",
    "    vect_dict = {'bow': None, 'svd': None, 'w2v': None}\n",
    "    classifiers = ['svm', 'random_forest']\n",
    "    for vectorizer in corpus_dict:\n",
    "        model, vect_corpus = vectorize(corpus, method=vectorizer)\n",
    "        vect_dict[vectorizer] = model\n",
    "        corpus_dict[vectorizer].append(vect_corpus)\n",
    "\n",
    "    # Train, evaluate classifiers and format results properly\n",
    "    scores = []\n",
    "    combinations = list(itertools.product(corpus_dict.values(), classifiers))\n",
    "    for current_corpus, classifier in combinations:\n",
    "        scores.append(train_evaluate_classifier(current_corpus[0], labels, classifier))\n",
    "\n",
    "\n",
    "\n",
    "    # Use ridge classifier as custom method for beating the benchmark\n",
    "    tfidf_vect, tfidf_corpus = vectorize(corpus, method='tfidf')\n",
    "    ridge_clf, ridge_score = train_evaluate_classifier(tfidf_corpus, labels, clf='ridge')\n",
    "    scores.append(ridge_score)\n",
    "    formatted_scores = format_results(score_list=scores)\n",
    "\n",
    "    # Predict on test set and generate evaluation csvs\n",
    "    print(formatted_scores)\n",
    "    evaluation_file(formatted_scores)\n",
    "    test_ids, test_corpus = load_dataset(subset='test')\n",
    "    predictions = predict(test_corpus, ridge_clf, tfidf_vect)\n",
    "    testset_categories_file(test_ids, predictions)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e6f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e4f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60140a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
