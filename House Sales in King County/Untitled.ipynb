{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/m9/f2_xj5n17437mc076w7crp_c0000gn/T//RtmpCL1ofe/downloaded_packages\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/m9/f2_xj5n17437mc076w7crp_c0000gn/T//RtmpCL1ofe/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘numDeriv’, ‘SQUAREM’, ‘mnormt’, ‘lava’, ‘kernlab’, ‘CVST’, ‘DEoptimR’, ‘magic’, ‘psych’, ‘prodlim’, ‘DRR’, ‘Rcpp’, ‘robustbase’, ‘sfsmisc’, ‘geometry’, ‘iterators’, ‘broom’, ‘ipred’, ‘dimRed’, ‘lubridate’, ‘timeDate’, ‘ddalpha’, ‘gower’, ‘RcppRoll’, ‘foreach’, ‘ModelMetrics’, ‘recipes’\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  There are binary versions available but the source versions are later:\n",
      "           binary source needs_compilation\n",
      "kernlab    0.9-25 0.9-26              TRUE\n",
      "robustbase 0.92-8 0.93-0              TRUE\n",
      "ddalpha     1.3.2  1.3.3              TRUE\n",
      "\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/m9/f2_xj5n17437mc076w7crp_c0000gn/T//RtmpCL1ofe/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "installing the source packages ‘kernlab’, ‘robustbase’, ‘ddalpha’\n",
      "\n",
      "Warning message in install.packages(\"caret\"):\n",
      "“installation of package ‘kernlab’ had non-zero exit status”Warning message in install.packages(\"caret\"):\n",
      "“installation of package ‘robustbase’ had non-zero exit status”Warning message in install.packages(\"caret\"):\n",
      "“installation of package ‘ddalpha’ had non-zero exit status”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/m9/f2_xj5n17437mc076w7crp_c0000gn/T//RtmpCL1ofe/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 3.4.2”\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Warning message:\n",
      "“package ‘caret’ was built under R version 3.4.4”Loading required package: lattice\n",
      "Warning message in as.POSIXlt.POSIXct(Sys.time()):\n",
      "“unknown timezone 'zone/tz/2018c.1.0/zoneinfo/Asia/Kolkata'”"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package or namespace load failed for ‘caret’ in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n there is no package called ‘ddalpha’\n",
     "output_type": "error",
     "traceback": [
      "Error: package or namespace load failed for ‘caret’ in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n there is no package called ‘ddalpha’\nTraceback:\n",
      "1. library(caret)",
      "2. tryCatch({\n .     attr(package, \"LibPath\") <- which.lib.loc\n .     ns <- loadNamespace(package, lib.loc)\n .     env <- attachNamespace(ns, pos = pos, deps)\n . }, error = function(e) {\n .     P <- if (!is.null(cc <- conditionCall(e))) \n .         paste(\" in\", deparse(cc)[1L])\n .     else \"\"\n .     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n .         sQuote(package), P, conditionMessage(e))\n .     if (logical.return) \n .         message(paste(\"Error:\", msg), domain = NA)\n .     else stop(msg, call. = FALSE, domain = NA)\n . })",
      "3. tryCatchList(expr, classes, parentenv, handlers)",
      "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "5. value[[3L]](cond)",
      "6. stop(msg, call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "\n",
    "############################# DATA PRE-PROCESSING ############################################\n",
    "\n",
    "#DATA PRE-PROCESSING IS THE MAJOR INITIAL CHALLENGE IN DATA SCIENCE PROJECT.\n",
    "#DATA PRE-PRECESSING  CONSUMES AROUND 80% OF TIME IN A PROJECT.\n",
    "#ONE OF THE INITIAL AND MAJOR SKILL NEEDED IN ANY DATA SCIENCE PROJECT IS DATA PRE-PROCESSING.\n",
    "#DATA PRE-PROCESSING IS ALWAYS DEPENDS ON DATA SCIENTIST INTUTION.\n",
    "#ALWAYS! REMEMBER THE GARBAGE IN AND GARBAGE OUT CONCEPT.\n",
    "#LET'S GET STARTED.\n",
    "\n",
    "\n",
    "############################# LOAD THE DATASET ##############################################\n",
    "\n",
    "house_us = read.csv(file=\"Datasets/kc_house_data.csv\")\n",
    "\n",
    "# THE FIRST STEP FOR DATA PRE-PROCESSING IS TO UNDERSTAND THE DATA.\n",
    "# YOU SHOULD HAVE A KNOWLEDGE ON CLIENT BUSINESS AND THEIR DATA.\n",
    "# WE DO DATA PRE-PROCESSING FOR ALGORITHM IN ORDER TO GET ACCURACY OUT OF IT.\n",
    "# SOME TIMES YOU DON'T SOME ATTRIBUTES,SO FEEL FREE TO ASK THE CLIENT ABOUT IT.\n",
    "# ACCEPT THE FACT THAT,YOUR CLIENT KNOWS BETTER ABOUT THEIR BUSSINESS THAN YOU.\n",
    "# ELSE YOU ENDED UP WITH EGOISTIC ISSUES.\n",
    "# WELL! ENOUGH OF BUSSINESS EHITCS RULES.\n",
    "# LET'S STICK TO THE DATA SCIENCE JOB.\n",
    "\n",
    "# SOME OF THE IMPORTANT STEPS WE NEED TAKE CARE ABOUT IN SEQUENCE WISE OR YOU CAN SAY SOME\n",
    "# OF THE THUMB RULE FOR DATA ANALYSING AND DATA PRE-PROCESSING ARE VERY IMP TO KNOW.\n",
    "# LET'S GET TO KNOW THEM.\n",
    "\n",
    "#1 ALWAYS SPEND TREMENDOUS TIME IN DATA UNDERSTANDING AND DATA ATTRIBUTES,\n",
    "#  THAT WILL LEAD YOU IN HAPPY ENDING.\n",
    "\n",
    "#2. TRY TO KNOW MORE ABOUT THEIR ATTRIBUTES.WHEN I SAY ATTRIBUTES, IT INCLUDES ALL KIND \n",
    "#   OF INFORMATION.\n",
    "\n",
    "#3  CHECK DATA TYPES,DISTRIBUTION,MISSING VALUES,DUPLICATE ROWS,DUPLICATE COLMNS,\n",
    "#   SCALE OF VARIABLE,SUMMARY,RANGE,OUTLIERS,DIMENSIONS,NOISE,INF,NEGATIVE VALUES.\n",
    "\n",
    "#4. OUTLIERS NOT ALWAYS A BAD THING,IT MIGHT BE A GOOD THING,IF IT IS GENUINE DATA.\n",
    "\n",
    "#5. VARIABLE'S DATA SHOULD BE ON SAME SCALE OR SAME UNIT.\n",
    "\n",
    "#6. REMOVE THE NON-INFORMATIVE COLUMNS AND ALSO DON'T INCLUDE MULTICOLLINEAR ATTRIBUTES.\n",
    "\n",
    "#7. SCALING(MIN-MAX),STANDARDIZING(Z-SCORE),BINNING(GROUPING IN DIFFERENT BUCKETS).\n",
    "\n",
    "#8. REMOVING OUTLIERS IS NOT RECOMMENDED.\n",
    "\n",
    "#9. IMPUTATION SHOULD BE APPROPRIATE AND ALWAYS BASED ON BUSINESS UNDERSTANDING.\n",
    "\n",
    "#10 HANDLE MULTI-CLASS COLUMN.\n",
    "\n",
    "#11 EXPLORATORY DATA ANALYSIS SHOULD BE DONE FOR A PURPOSE,NOT FOR A RANDOM PLOT.\n",
    "#   VISUALIZATION IS A MAIN TECHNIQUE TO DRAW INTUTION AND CONCULUDE WITH SOME UNDERSTANDING.\n",
    "\n",
    "#12 WE SHOULD KNOW HOW TO EXTRACT INFORMATION FROM DATA.\n",
    "#   DATES AND ZIP CODES ARE NOT ALWAYS AVOIDABLE,WE SHOULD KNOW HOW TO EXTRACT,\n",
    "#   INFORMATION FROM THOSE KIND OF VARIABLES.\n",
    "\n",
    "#13 REAL TIME DATA ARE NOISY AND DIRTY,SOME TIMES YOU MAY ENCOUNTER SOME SITUATIONS LIKE,\n",
    "#   A VARIABLE CONTAINS MULTI DATA TYPES. :-P\n",
    "\n",
    "#14 SOMETIMES YOU MAY NOTICE THAT AFTER TRANSFORMATION,YOUR OUTLIERS DECREASES.\n",
    "#   IF THEN ALSO YOU DATA HAVE LOTS OF OUTLIERS THEN YOU CAN USE CAPPING.(AVOID REMOVING OUTLIERS)\n",
    "\n",
    "#15 LAST BUT NOT THE LEAST,INFERENCE IS ALWAYS THE KEY SOLVE PROBLEMS IN DATA SCIENCE.\n",
    "\n",
    "\n",
    "############################### LET'S CHECK OUR DATA ######################################\n",
    "\n",
    "install.packages(\"ggplot2\")\n",
    "install.packages(\"dplyr\")\n",
    "install.packages(\"caret\")\n",
    "install.packages(\"corrplot\")\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(caret)\n",
    "library(corrplot)\n",
    "\n",
    "dim(house_us)\n",
    "\n",
    "summary(house_us)\n",
    "\n",
    "str(house_us)\n",
    "\n",
    "head(house_us,5)\n",
    "\n",
    "###### CHECK OUT \"ID\" COLUMN ####\n",
    "\n",
    "# table(house_us$id) @ (not recommended)\n",
    "\n",
    "sum(table(house_us$id))\n",
    "\n",
    "# SINCE ALL ROWS IN \"ID\" COLUMNS CONTAINS UNIQUE VALUE,SO WE SHOULD'NT BE USING \n",
    "# THIS COLM,BECAUSE THIS COLUMN IS NOT GIVING ANY INFORMATION.\n",
    "\n",
    "################################ DROPING ID COLM #########################################\n",
    "\n",
    "house_us$id = NULL\n",
    "\n",
    "############################### CHECK DATE COLUMN ########################################\n",
    "\n",
    "## DATE COLUMN CONTAINS BIZZARE FORMAT LIKE \"20151214T000000\" WE NEED TO SUBSTRING LAST PART.\n",
    "\n",
    "?substr\n",
    "\n",
    "house_us$date = substr(house_us$date,1,8)\n",
    "\n",
    "############################# manupulating dates ###########################################\n",
    "\n",
    "dates = house_us$date\n",
    "\n",
    "year = substr(dates,1,4)\n",
    "head(year)\n",
    "\n",
    "month = substr(dates,5,6)\n",
    "head(month)\n",
    "\n",
    "day = substr(dates,7,8)\n",
    "head(day)\n",
    "\n",
    "############################# check attributes ###########################################\n",
    "\n",
    "colnames(house_us)\n",
    "\n",
    "############################ add month,day,year colm to data set ##########################\n",
    "\n",
    "house_us$year = year\n",
    "house_us$month = month\n",
    "house_us$day = day\n",
    "\n",
    "################################load data manupulation package ###########################\n",
    "\n",
    "install.packages(\"lubridate\")\n",
    "install.packages(\"tidyr\")\n",
    "\n",
    "library(lubridate)\n",
    "library(tidyr)\n",
    "\n",
    "date1 = unite(house_us,date1,day,month,year,sep = \"-\")\n",
    "head(date1)\n",
    "\n",
    "dates_1 = date1$date1\n",
    "\n",
    "head(dates_1)\n",
    "\n",
    "house_us$date = dates_1\n",
    "\n",
    "### since,date colm is not going to add information because those dates are dummy dates###\n",
    "### we should remove this colm ###\n",
    "\n",
    "house_us = subset(house_us,select = -c(date,year,month,day))\n",
    "\n",
    "###################### now we have 19 colm and 21613 rows #######################################################\n",
    "\n",
    "#### CHECK NA'S IN DATASET ###\n",
    "\n",
    "any(is.na(house_us)) # FALSE\n",
    "\n",
    "sum(is.na(house_us)) # 0\n",
    "\n",
    "sum(!complete.cases(house_us))\n",
    "\n",
    "### since there is no missing values,so no need to any kind of imputation ###\n",
    "\n",
    "### i have noticed somethin,colm \"Long\" has negative values ###\n",
    "### i don't know why this colm has negative values #### let's see\n",
    "\n",
    "range(house_us$long)\n",
    "summary(house_us$long)\n",
    "sum(table(house_us$long))\n",
    "unique(house_us$long)\n",
    "\n",
    "### \"long\" colm has duplicate values ranging -122 to -122.5 ####\n",
    "### dropping \"long\" colm ###\n",
    "\n",
    "house_us$long=NULL\n",
    "\n",
    "# Correlation plot of different features and price\n",
    "\n",
    "cr <- cor(house_us)\n",
    "\n",
    "\n",
    "corrplot(cr, type=\"full\", method = \"circle\", main=\"Correlation\")\n",
    "\n",
    "corrplot(cr, type=\"full\", method = \"number\", main=\"Correlation\")\n",
    "\n",
    "# Print Correlation coefficients\n",
    "\n",
    "print(round(cr, digits=2))\n",
    "\n",
    "# Picking up some of the features that are highly correlated with price\n",
    "# Correlation between price and sqft_living is (0.7)\n",
    "# Correlation between price and grade is (0.67)\n",
    "# Correlation between price and sqft_above is (0.61)\n",
    "# Correlation between price and sqft_living15 is (0.59)\n",
    "# Correlation between price and bathrooms is (0.53)\n",
    "\n",
    "# Now, let us evaluate the correlation of the above features with each others for multicolinearity \n",
    "# Correlation between sqft_living and sqft_above is (0.88)\n",
    "# Correlation between sqft_living and sqft_living15 is (0.76)\n",
    "# Correlation between sqft_living and grade is (0.76)\n",
    "# Correlation between sqft living and bathrooms is (0.75)\n",
    "\n",
    "############################## CHECK TRANSFORMATION OF VARIABLES ##########################\n",
    "\n",
    "par(mfrow=c(3,6))\n",
    "for (i in 1:18) {\n",
    "  hist(house_us[,i],main = names(house_us[i]),col=\"steelblue\")\n",
    "}\n",
    "\n",
    "### most of the variables are right skewed,since we are performing linear regression on price\n",
    "### linear regression assumption is,all variable should be normally distributed ###\n",
    "### so we need to perform normalization ####\n",
    "\n",
    "hist(log(house_us$price)) ### close to normal distribution ###\n",
    "\n",
    "house_us$price_log = log(house_us$price)\n",
    "\n",
    "hist(log(house_us$sqft_above))## close to normal distribution ###\n",
    "\n",
    "house_us$sqft_above_log = log(house_us$sqft_above)\n",
    "\n",
    "#house_us$sqft_above=NULL\n",
    "\n",
    "hist(log(house_us$sqft_living))\n",
    "\n",
    "house_us$sqft_living_log = log(house_us$sqft_living)\n",
    "\n",
    "#house_us$sqft_living=NULL\n",
    "\n",
    "hist(log(house_us$sqft_living15)) #not bad#\n",
    "\n",
    "house_us$sqft_living15_log = log(house_us$sqft_living15)\n",
    "\n",
    "#house_us$sqft_living15=NULL\n",
    "\n",
    "hist(log(house_us$sqft_lot))\n",
    "\n",
    "house_us$sqft_lot_log = log(house_us$sqft_lot)\n",
    "\n",
    "#house_us$sqft_lot = NULL\n",
    "\n",
    "hist(log(house_us$sqft_basement))#not bad #\n",
    "hist(house_us$sqft_basement)\n",
    "\n",
    "house_us$sqft_basement_log = log(house_us$sqft_basement)\n",
    "#house_us$sqft_basement=NULL\n",
    "\n",
    "# Plotting price vs all other features.\n",
    "\n",
    "par(mfrow=c(3,6))\n",
    "for(i in 2:18){\n",
    "  plot(house_us[,i], house_us$price, main=names(house_us[i]), ylab=names(house_us$price), xlab=\"\", col='steelblue')\n",
    "}\n",
    "\n",
    "\n",
    "# Seems waterfront, floors, view, condition, grade, yr_built, yr_renovated, zipcode, lat,can also be given a thought from categorical perspective. \n",
    "# Running a quick boxplot on these to see the price quantiles\n",
    "par(mfrow=c(1,1))\n",
    "for(i in c(2,3,6,7,8,9,10,15)){\n",
    "  boxplot(house_us[,1]~house_us[,i], xlab='comparision', main=names(house_us[i]), col=c(\"blue\",\"red\"))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# bedrooms:   median prices across bedrooms have less variation. Notice the extreme.\n",
    "# bathrooms:  median pricee seems to be increasing but there are categorical lows also.\n",
    "# floors:     shows categorical variation in median price\n",
    "# waterfront: median price is higher with waterfront\n",
    "# view:       little median price variation\n",
    "# condition:  has some effect on median price\n",
    "# grade:      median prices show linear trend\n",
    "# zipcode:    some of the zipcodes command higher prices\n",
    "\n",
    "# Now back to bedroom extremes that we noticed.\n",
    "# bedrooms seem to have some extreme values. Checking a quick data distribution.\n",
    "\n",
    "par(mfrow = c(1,2))\n",
    "hist(house_us$bedrooms, breaks = 30, xlab = \"\", col = \"lightsteelblue\",  main = \"Bedrooms\")\n",
    "plot(density(house_us$bedrooms), xlab=\"\", col = \"steelblue\", main=\"Bedrooms\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Checking bedroom extremes as distibution is very skewed\n",
    "# there is two record of bedroom having 11 & 33 seems odd\n",
    "\n",
    "print(subset(house_us, house_us$bedrooms > 10))\n",
    "\n",
    "\n",
    "# There is one record each for bedroom 11 and 33. \n",
    "# 33 bedroom house has 1.75 bathrooms, sqft_living is also very less. Seems little odd.\n",
    "# I suspect a data entry error here. Lets calculate the mean sqft_living of 3 bedroom house.\n",
    "\n",
    "bed_room <- subset(house_us,house_us$bedrooms == 3)\n",
    "\n",
    "print(tapply(bed_room$sqft_living_log, bed_room$bedrooms, mean)) #sqft_living\n",
    "\n",
    "# Mean sqft_living of 3 bedroom house is approx 1805 whereas for 33 bedrooms it is 1620.\n",
    "# since i will remove,those two records which i beleive data entry error.\n",
    "\n",
    "new_data = house_us[house_us$bedrooms<=10,]\n",
    "dim(new_data)\n",
    "\n",
    "############################# checking distribution of bathrooms #########################\n",
    "### density plot\n",
    "### scatter plot between pice and bathroom\n",
    "\n",
    "\n",
    "par(mfrow = c(1,3))\n",
    "hist(new_data$bathrooms, breaks = 20, xlab = \"\", col = \"lightsteelblue\",  main = \"Bathrooms\")\n",
    "plot(density(new_data$bedrooms), xlab=\"\", col = \"steelblue\", main=\"Bathrooms\")\n",
    "scatter.smooth(new_data$bathrooms, new_data$price, col=\"steelblue\", xlab=\"\", ylab=\"Price\",main=\"Bathrooms\",lpars=list(col=\"red\", lwd=3))\n",
    "\n",
    "# Distribution looks skewed.\n",
    "# Lets see what is the ratio of bedrooms >= 6\n",
    "\n",
    "print(prop.table(table(new_data$bathrooms >= 6)))\n",
    "\n",
    "# Only 0.0007% data has 6 bathrooms or more with few readings in each category. That too, with \n",
    "# spread out price range. For example, there are two reading with 8 bedrooms; one with very low price \n",
    "# and another with very high. This is the reason why we ware observing a higher median price with \n",
    "# increase in bedrooms.\n",
    "\n",
    "# For numeric, will drop highly correlated data amongst features\n",
    "# Will turn categorical data into factors. In R regression models, turnig them to factors has similar effect as dummy vars.\n",
    "\n",
    "\n",
    "############################### converting data types ##################################\n",
    "\n",
    "# converting to factors\n",
    "\n",
    "new_data$zipcode <- as.factor(new_data$zipcode)\n",
    "new_data$grade <- as.factor(new_data$grade)\n",
    "new_data$waterfront <- as.factor(new_data$waterfront)\n",
    "new_data$floors <- as.factor(new_data$floors)\n",
    "new_data$bedrooms <- as.factor(new_data$bedrooms)\n",
    "new_data$yr_built<- as.numeric(new_data$yr_built)\n",
    "#### check structure of data ######\n",
    "\n",
    "glimpse(new_data)\n",
    "\n",
    "## i am thinking that, we should make feature engg.\n",
    "### suppose we have an attribute called \"yr_built\"\n",
    "### if we substract 2018 - \"yr_built\" we can  find age of house ###\n",
    "\n",
    "y = rep(x = 2018,21611)\n",
    "head(y)\n",
    "class(y)\n",
    "length(y)\n",
    "\n",
    "### add colmn\n",
    "\n",
    "new_data$year_2018 = y\n",
    "\n",
    "########################## substract yr_built - yr_2018 ##############################\n",
    "\n",
    "install.packages(\"Hmisc\")\n",
    "library(Hmisc)\n",
    "\n",
    "new_data1 = new_data[,c(9,19)]\n",
    "\n",
    "head(new_data1)\n",
    "\n",
    "glimpse(new_data1)\n",
    "\n",
    "new_data1$house_age = new_data1$year_2018 - new_data1$yr_built\n",
    "\n",
    "############################ add colmn to newdata #######################################\n",
    "\n",
    "\n",
    "#new_data$house_aged = new_data1$house_age\n",
    "\n",
    "#################################### splitting data ###############################################\n",
    "install.packages(\"caTools\")\n",
    "library(caTools)\n",
    "set.seed(123)\n",
    "split= sample.split(Y = new_data$price_log,SplitRatio = 0.7)\n",
    "training_data = subset(new_data,split==TRUE)\n",
    "tEST_data = subset(new_data,split==FALSE)\n",
    "\n",
    "\n",
    "################################# MODELLING ############################################\n",
    "\n",
    "model1 = lm(price_log~sqft_living_log + grade + waterfront + view + condition +zipcode+bathrooms+bedrooms,data = training_data)\n",
    "summary(model1)\n",
    "\n",
    "#### it seems bedrooms are not significant, so remove those colm ####\n",
    "\n",
    "model2 = lm(price_log~sqft_living_log + waterfront+grade+house_aged + view + condition +zipcode,data = training_data)\n",
    "summary(model2)\n",
    "\n",
    "############################## PREDICTION ##############################################\n",
    "\n",
    "PREDS = predict(model2,newdata = tEST_data)\n",
    "\n",
    "actual_predictn = data.frame(obs = tEST_data$price_log,prediction = PREDS)\n",
    "\n",
    "actual_predictn\n",
    "\n",
    "\n",
    "############################### plotting ################################################\n",
    "\n",
    "plot(actual_predictn$obs,type = \"l\",lty=1.8,col=\"green\")\n",
    "lines(PREDS,type = \"l\",col=\"blue\")\n",
    "\n",
    "############################### prediction on actual price ##############################\n",
    "\n",
    "actual_predictn$actual_price = tEST_data$price\n",
    "\n",
    "actual_predictn$actual_pred = tEST_data$price_log*2.718\n",
    "\n",
    "################################# check difference #####################################\n",
    "\n",
    "actual_predictn$difference= actual_predictn$actual_price - actual_predictn$actual_pred\n",
    "\n",
    "#################################### difference2 ###################################\n",
    "\n",
    "actual_predictn$difference2= actual_predictn$obs - actual_predictn$prediction\n",
    "\n",
    "\n",
    "\n",
    "################################## RMSE ###################################################\n",
    "\n",
    "RMSE = sqrt(mean((actual_predictn$obs - actual_predictn$prediction**2)^2))\n",
    "\n",
    "RMSE\n",
    "\n",
    "\n",
    "################################# RMSE ON ACTUAL DATA ###################################\n",
    "\n",
    "RMSE2 = sqrt(mean((actual_predictn$actual_price - actual_predictn$actual_pred**2)^2))\n",
    "\n",
    "RMSE2\n",
    "\n",
    "\n",
    "################################ MODEL ON ACTUAL PRICE ##################################\n",
    "\n",
    "\n",
    "model3 = lm(price~sqft_living_log + waterfront+grade+house_aged + view + condition +zipcode,data = training_data)\n",
    "summary(model3)\n",
    "\n",
    "plot(model3)\n",
    "\n",
    "predsss = predict(model3,newdata = tEST_data)\n",
    "\n",
    "predsss\n",
    "\n",
    "\n",
    "aaaa = data.frame(observation=tEST_data$price,predx=predsss)\n",
    "\n",
    "aaaa$difference3 = aaaa$observation-aaaa$predx\n",
    "\n",
    "plot(aaaa$observation,type = \"l\",lty=1.3,col=\"blue\")\n",
    "\n",
    "lines(aaaa$predx,lty=1.3,col=\"green\")\n",
    "\n",
    "################################# RMSE ###################################################\n",
    "\n",
    "\n",
    "RMSE3 = sqrt(mean(aaaa$observation - aaaa$predx**2)^2)\n",
    "RMSE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘robustbase’\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  There are binary versions available but the source versions are later:\n",
      "           binary source needs_compilation\n",
      "robustbase 0.92-8 0.93-0              TRUE\n",
      "ddalpha     1.3.2  1.3.3              TRUE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "installing the source packages ‘robustbase’, ‘ddalpha’\n",
      "\n",
      "Warning message in install.packages(\"ddalpha\"):\n",
      "“installation of package ‘robustbase’ had non-zero exit status”Warning message in install.packages(\"ddalpha\"):\n",
      "“installation of package ‘ddalpha’ had non-zero exit status”"
     ]
    }
   ],
   "source": [
    "install.packages(\"ddalpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
