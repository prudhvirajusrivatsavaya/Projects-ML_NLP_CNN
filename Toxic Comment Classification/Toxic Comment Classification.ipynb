{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset = pd.read_csv(\"Datasets/train.csv\")\n",
    "master_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset has 159571 rows and 8 variables, which has a comment_text variable having textual data followed by 5 target variables. This is a multi label classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Drop Duplicates\n",
    "The function fn_del_dup_rows takes a dataframe as in input and checks for any duplicate records in the dataframe. If found, the duplicate rceords are dropped by preserving only one of the records. \n",
    "Next, the if any empty rows are found, the entire rows are dropped from the dataframe. The function returns two dataframes - the original dataframe and cleaned dataframe after removing duplicates and empty records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found\n",
      "No empty records found\n"
     ]
    }
   ],
   "source": [
    "def fn_del_dup_rows(df):\n",
    "    duplicated_df = df.copy()\n",
    "    tot_rows = duplicated_df.shape[0]\n",
    "    \n",
    "    # Dropping duplicate records\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    distinct_rows = df.shape[0]\n",
    "    if(distinct_rows<tot_rows):\n",
    "        print(\"Duplicates found. Total duplicates\",tot_rows-distinct_rows)\n",
    "    else:\n",
    "        print(\"No duplicates found\")\n",
    "    \n",
    "    #Dropping empty records\n",
    "    tot_rows = df.shape[0]\n",
    "    df.dropna(axis=0, how='all',inplace=True)\n",
    "    distinct_rows = df.shape[0]\n",
    "    if(distinct_rows<tot_rows):\n",
    "        print(\"Empty records found. Total empty records\",tot_rows-distinct_rows)\n",
    "    else:\n",
    "        print(\"No empty records found\")\n",
    "    return duplicated_df,df\n",
    "\n",
    "duplicated_df,master_dataset = fn_del_dup_rows(master_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               object\n",
       "comment_text     object\n",
       "toxic             int64\n",
       "severe_toxic      int64\n",
       "obscene           int64\n",
       "threat            int64\n",
       "insult            int64\n",
       "identity_hate     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Datatype Conversion\n",
    "Looks like pandas has considered almost all variables as float and 2 variables as objects. Let's assign the actual datatypes to each of the variables. \n",
    "\n",
    "The function get_uniq_vals takes a dataframe as an input and returns a Series of unique values in each column. This helps in identifying the categorical variables in the dataset.\n",
    "\n",
    "The function fn_set_dtypes takes 5 parameters as inputs - the dataframe, a list of all categorical variable names, a list of integers and a list of floats and a list of objects. \n",
    "\n",
    "The function returns a dataframe by assigning the appropriate datatype to each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 object\n",
       "comment_text       object\n",
       "toxic            category\n",
       "severe_toxic     category\n",
       "obscene          category\n",
       "threat           category\n",
       "insult           category\n",
       "identity_hate    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn_set_dtypes(df,categories_,ints_,floats_,objects_):\n",
    "    for category_ in categories_:\n",
    "        df[category_] = df[category_].astype(\"category\")\n",
    "        \n",
    "    for int_ in ints_:\n",
    "        df[int_] = df[int_].astype(\"int64\")\n",
    "        \n",
    "    for float_ in floats_:\n",
    "        df[float_] = df[float_].astype(\"float64\")\n",
    "        \n",
    "    for object_ in objects_:\n",
    "        df[object_] = df[object_].astype(\"object\")\n",
    "    return df\n",
    "\n",
    "categories_=['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "ints_=[]\n",
    "floats_=[]\n",
    "objects_=['comment_text','id']\n",
    "master_dataset = fn_set_dtypes(master_dataset,categories_,ints_,floats_,objects_)\n",
    "master_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing Value Treatment\n",
    "\n",
    "Let's check if any variable has missing values in the dataset and use a correct method to impute.\n",
    "\n",
    "The function fn_get_missing_vals takes a dataframe and returns a dataframe which contains the list of all variables and number of missing values in each variable along with percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Val Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Val Count, Percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn_get_missing_vals(df,cols_):\n",
    "    df=df[cols_]\n",
    "    n_rows = df.shape[0]\n",
    "    miss_val_cnts = df.isna().sum()\n",
    "    miss_vals = pd.DataFrame(miss_val_cnts[miss_val_cnts>0],columns=['Missing Val Count'])\n",
    "    miss_vals['Percentage'] = miss_vals['Missing Val Count']*100/n_rows\n",
    "    return miss_vals\n",
    "\n",
    "fn_get_missing_vals(master_dataset,categories_+ints_+floats_+objects_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! There are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "5         \"\\n\\nCongratulations from me as well, use the ...\n",
       "6              COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
       "7         Your vandalism to the Matt Shirvington article...\n",
       "8         Sorry if the word 'nonsense' was offensive to ...\n",
       "9         alignment on this subject and which are contra...\n",
       "10        \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...\n",
       "11        bbq \\n\\nbe a man and lets discuss it-maybe ove...\n",
       "12        Hey... what is it..\\n@ | talk .\\nWhat is it......\n",
       "13        Before you start throwing accusations and warn...\n",
       "14        Oh, and the girl above started her arguments w...\n",
       "15        \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...\n",
       "16        Bye! \\n\\nDon't look, come or think of comming ...\n",
       "17         REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski\n",
       "18        The Mitsurugi point made no sense - why not ar...\n",
       "19        Don't mean to bother you \\n\\nI see that you're...\n",
       "20        \"\\n\\n Regarding your recent edits \\n\\nOnce aga...\n",
       "21        \"\\nGood to know. About me, yeah, I'm studying ...\n",
       "22        \"\\n\\n Snowflakes are NOT always symmetrical! \\...\n",
       "23        \"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...\n",
       "24        \"\\n\\nRe-considering 1st paragraph edit?\\nI don...\n",
       "25        Radial symmetry \\n\\nSeveral now extinct lineag...\n",
       "26        There's no need to apologize. A Wikipedia arti...\n",
       "27        Yes, because the mother of the child in the ca...\n",
       "28        \"\\nOk. But it will take a bit of work but I ca...\n",
       "29        \"== A barnstar for you! ==\\n\\n  The Real Life ...\n",
       "                                ...                        \n",
       "159541    Your absurd edits \\n\\nYour absurd edits on gre...\n",
       "159542    maybe he's got better things to do than spend ...\n",
       "159543    scrap that, it does meet criteria and its gone...\n",
       "159544                                  You could do worse.\n",
       "159545    , 7 March 2011 (UTC)\\nAre you also User:Bmatts...\n",
       "159546    \"\\n\\nHey listen don't you ever!!!! Delete my e...\n",
       "159547                       Thank you very, very much.  ·✆\n",
       "159548                          Talkback: 15 September 2012\n",
       "159549                           2005 (UTC)\\n 06:35, 31 Mar\n",
       "159550    i agree/ on another note lil wayne is a talent...\n",
       "159551    While about half the references are from BYU-I...\n",
       "159552    Prague Spring \\n\\nI think that Prague Spring d...\n",
       "159553    I see this as having been merged; undoing one ...\n",
       "159554    and i'm going to keep posting the stuff u dele...\n",
       "159555    \"\\n\\nHow come when you download that MP3 it's ...\n",
       "159556    I'll be on IRC, too, if you have a more specif...\n",
       "159557    It is my opinion that that happens to be off-t...\n",
       "159558    Please stop removing content from Wikipedia; i...\n",
       "159559    Image:Barack-obama-mother.jpg listed for delet...\n",
       "159560    \"Editing of article without Consensus & Remova...\n",
       "159561    \"\\nNo he did not, read it again (I would have ...\n",
       "159562    \"\\n Auto guides and the motoring press are not...\n",
       "159563    \"\\nplease identify what part of BLP applies be...\n",
       "159564    Catalan independentism is the social movement ...\n",
       "159565    The numbers in parentheses are the additional ...\n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"== A barnstar for you! ==\\n\\n  The Real Life Barnstar lets us be the stars\\n   \"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset.loc[29,'comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
