{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn=pd.read_csv(\"Datasets/Teleco_Cust_Attr.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Type Conversion\n",
    "churn[\"SeniorCitizen\"]=churn[\"SeniorCitizen\"].astype(object)\n",
    "\n",
    "## Replacing few values \n",
    "churn.loc[churn.OnlineSecurity==\"No internet service\",\"OnlineSecurity\"]=\"No\"\n",
    "churn.loc[churn.OnlineBackup==\"No internet service\",\"OnlineBackup\"]=\"No\"\n",
    "churn.loc[churn.DeviceProtection==\"No internet service\",\"DeviceProtection\"]=\"No\"\n",
    "churn.loc[churn.TechSupport==\"No internet service\",\"TechSupport\"]=\"No\"\n",
    "churn.loc[churn.StreamingTV==\"No internet service\",\"StreamingTV\"]=\"No\"\n",
    "churn.loc[churn.StreamingMovies==\"No internet service\",\"StreamingMovies\"]=\"No\"\n",
    "churn.loc[churn.MultipleLines==\"No phone service\",\"MultipleLines\"]=\"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping few columns\n",
    "churn.drop(\"customerID\", axis = 1, inplace=True)\n",
    "churn.drop(\"gender\",axis=1,inplace=True)\n",
    "#churn.drop(\"PhoneService\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering\n",
    "churn.insert(0, \"Charges\", 0)\n",
    "total_rows = churn['Churn'].count()\n",
    "for i in range(0,total_rows):\n",
    "    churn.loc[i,\"Charges\"]=churn.loc[i,\"tenure\"]*churn.loc[i,\"MonthlyCharges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.drop(\"TotalCharges\", axis = 1,  inplace=True)\n",
    "churn.drop(\"tenure\",axis=1,inplace=True)\n",
    "churn.drop(\"MonthlyCharges\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lc = LabelEncoder()\n",
    "for i in churn.columns:\n",
    "    if(churn[i].dtype.name==\"object\"):\n",
    "        churn[i] = churn[i].astype(\"category\")\n",
    "        churn[i] = lc.fit_transform(churn[i])\n",
    "        churn[i] = churn[i].astype(\"category\")\n",
    "        \n",
    "# master_dataset.head(7)\n",
    "#churn.dtypes\n",
    "churn['SeniorCitizen']=churn['SeniorCitizen'].astype('uint8')\n",
    "churn['Partner']=churn['Partner'].astype('uint8')\n",
    "churn['Dependents']=churn['Dependents'].astype('uint8')\n",
    "churn['PaperlessBilling']=churn['PaperlessBilling'].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oe = OneHotEncoder()\n",
    "churn_cat=[]\n",
    "churn_ncat=[]\n",
    "for i in churn.columns:\n",
    "    if(churn[i].dtype.name==\"category\"):\n",
    "        if(len(churn[i].unique()) > 1):\n",
    "            churn_cat.append(i) \n",
    "        else:\n",
    "            churn_ncat.append(i)\n",
    "    else:\n",
    "        churn_ncat.append(i)\n",
    "                 \n",
    "churn_cat = churn[churn_cat]\n",
    "churn_ncat = churn[churn_ncat]\n",
    "\n",
    "churn_cat = pd.get_dummies(churn_cat,drop_first=True)\n",
    "fn_dataset = pd.merge(churn_cat,churn_ncat,left_index=True, right_index=True)\n",
    "X = fn_dataset.iloc[:,:-1]\n",
    "Y = fn_dataset.iloc[:,-1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.6974630821658463\n",
      "                     0         0\n",
      "0       PhoneService_1 -0.019751\n",
      "1      MultipleLines_1  0.191331\n",
      "2    InternetService_1  0.533456\n",
      "3    InternetService_2 -0.619235\n",
      "4     OnlineSecurity_1 -0.315500\n",
      "5       OnlineBackup_1  0.174638\n",
      "6   DeviceProtection_1 -0.162525\n",
      "7        TechSupport_1 -0.069586\n",
      "8        StreamingTV_1  0.299932\n",
      "9    StreamingMovies_1  0.275867\n",
      "10          Contract_1 -0.256435\n",
      "11          Contract_2 -0.452693\n",
      "12     PaymentMethod_1  0.129785\n",
      "13     PaymentMethod_2  0.237514\n",
      "14     PaymentMethod_3 -0.219255\n",
      "15             Churn_1  0.372806\n",
      "16             Charges  0.000060\n",
      "17       SeniorCitizen  0.274235\n",
      "18             Partner  0.046561\n",
      "19          Dependents -0.065460\n",
      "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Confusion Matrix of Train Dataset\n",
      "[[1153  973]\n",
      " [ 625 2531]]\n",
      "Precision of Train Data 0.7223173515981736\n",
      "Rrecall of Train Data 0.8019645120405576\n",
      "Accuracy of Train Data 0.6974630821658463\n",
      "F1 Score of Train Data 0.76006006006006\n",
      "classification report of Train Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.54      0.59      2126\n",
      "          1       0.72      0.80      0.76      3156\n",
      "\n",
      "avg / total       0.69      0.70      0.69      5282\n",
      "\n",
      "Confusion Matrix of test Dataset\n",
      "[[388 358]\n",
      " [189 826]]\n",
      "Precision of Test Data 0.6976351351351351\n",
      "Rrecall of Test Data 0.8137931034482758\n",
      "Accuracy of Test Data 0.6893810335036911\n",
      "F1 Score of Test Data 0.7512505684402002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(penalty='l2',C=5)\n",
    "print(classifier)\n",
    "result=classifier.fit(X_train, y_train)\n",
    "print(classifier.score(X_train, y_train))\n",
    "coefficients = pd.concat([pd.DataFrame(X_train.columns),pd.DataFrame(np.transpose(result.coef_))], axis = 1)\n",
    "print(coefficients)\n",
    "\n",
    "print(result)\n",
    "y_pred_train = result.predict(X_train)\n",
    "y_pred_test = result.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "cm_train=confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusion Matrix of Train Dataset\")\n",
    "print(cm_train)\n",
    "TP=cm_train[1][1]\n",
    "FP=cm_train[0][1]\n",
    "FN=cm_train[1][0]\n",
    "TN=cm_train[0][0]\n",
    "precision_train=TP/(TP+FP)\n",
    "Recall_train=TP/(TP+FN)\n",
    "Accuracy_train=(TP+TN)/(TP+FP+TN+FN)\n",
    "F1_Score_train=(2*precision_train*Recall_train)/(precision_train+Recall_train)\n",
    "print(\"Precision of Train Data\",+precision_train)\n",
    "print(\"Rrecall of Train Data\",+Recall_train)\n",
    "print(\"Accuracy of Train Data\",+Accuracy_train)\n",
    "print(\"F1 Score of Train Data\",+F1_Score_train)\n",
    "\n",
    "print(\"classification report of Train Dataset\")\n",
    "classificaiton_report_train=classification_report(y_train,y_pred_train)\n",
    "print(classificaiton_report_train)\n",
    "\n",
    "cm_test=confusion_matrix(y_test,y_pred_test)\n",
    "print(\"Confusion Matrix of test Dataset\")\n",
    "print(cm_test)\n",
    "TP=cm_test[1][1]\n",
    "FP=cm_test[0][1]\n",
    "FN=cm_test[1][0]\n",
    "TN=cm_test[0][0]\n",
    "precision_test=TP/(TP+FP)\n",
    "Recall_test=TP/(TP+FN)\n",
    "Accuracy_test=(TP+TN)/(TP+FP+TN+FN)\n",
    "F1_Score_test=(2*precision_test*Recall_test)/(precision_test+Recall_test)\n",
    "print(\"Precision of Test Data\",+precision_test)\n",
    "print(\"Rrecall of Test Data\",+Recall_test)\n",
    "print(\"Accuracy of Test Data\",+Accuracy_test)\n",
    "print(\"F1 Score of Test Data\",+F1_Score_test)\n",
    "#print(\"classification report of Train Dataset\")\n",
    "#classificaiton_report_test=classification_report(y_test,y_pred_test)\n",
    "#print(classificaiton_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
